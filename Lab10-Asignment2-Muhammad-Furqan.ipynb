{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10 - Assignment 2\n",
    "At the end of the year there are many departments of the company that request different data, both to perform analytics and to generate external reports.\n",
    "\n",
    "The Data and Business Intelligence director has called his Data Engineering team and has listed the Dataset that they have to generate to respond to the different requests they have had.\n",
    "\n",
    "To carry out the work, they have different text files ingested from the different databases of the company's management systems. These are:\n",
    "\n",
    "1. \"transactions-asignment.csv\". It is the file with all the transactions for year 2018 with columns: TransactionID, CustomerID, Date, Product, Group, Amount, PaymentType, Country.\n",
    "2. \"customer-data-asignment.csv\". It is the file with columns: CustomerID, CardNumber. It contains the relationship between the customer and his credit card identity.\n",
    "3. \"country-vat.csv\". It is the file with columns: VAT, Country. It contains the relationship between each Country and the Value Added Tax which is applied for the products.\n",
    "4. The products are labeled by a tag: A to J.\n",
    "5. The groups contains: 'Food', 'Leisure', 'Restaurant', 'Gym', 'Gambling', 'Travel', 'Learning'.\n",
    "6. The payment type contains: 'Visa', 'Cash', 'American', 'PayPal', 'Mastercard', 'Check'.\n",
    "7. The countries where the transactions come from are: 'Italy', 'France', 'Germany', 'USA', 'Brasil', 'UK', 'Switzerland', 'Sweden', 'Denmark', 'Canada', 'Mexico', 'Russia'.\n",
    "\n",
    "The requested data reports are:\n",
    "1. The Product Marketing Department wants to analyze the monthly transactions by country respect to Group and respect to Product inside each Group. For this reason it need two DataFrames: one grouped by Group and other grouped by Product inside each Group. The columns for the first DataFrame should be: *Country, Month, Group, TotalMonth, AvgMonth, Number of Transactions*. And for the second one should be: *Country, Month, Group, Product, TotalMonth, AvgMonth, Number of Transactions*. How many records does each DataFrame?\n",
    "2. Could we say to Marketing Department which is the country and the month with the *highest total month amount* for Restaurant Group? How many transactions have been made for that Country and month?\n",
    "3. Could we say to Marketing Department which is the Product with the *highest total month amount* for Gambling Group and which is the Country and the month for that highest sale?\n",
    "4. The Financial Department needs to liquidate the VAT (the Amount for each transaction is gross, VAT for the country is included) for each country with the tax authority. Could we say to Financial Department which is the Country we should pay  the bigest VAT amount and the amount? And which is the Country we should pay the smaller one and the amount? \n",
    "5. Also they need to know the total amount for type of payment (except the payments in cash) to liquidate with their own bank. Could we say to Financial Department which is the amount paid for every payment type?\n",
    "6. Who is our best customer and what is his/her credit card number?\n",
    "7. Calculate the total income coming from USA by type of payment and from outside USA.\n",
    "8. Which is the relationship between the income from USA and from outside USA for every type of payment.\n",
    "\n",
    "Hint for 4: For the first Dataset about liquidate VAT you first shoul join the transactionsDF with countryVATDF, create a new column with the corresponding VAT for each transactions and after that to group by country and to agregate the sum on the new created column.\n",
    "\n",
    "For the second Dataset we should first filter by payment type different than 'Cash' and after that to group by payment type and aggregate the sum on Amount.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['SPARK_HOME'] = \"/Users/furqan/Downloads/spark-2.3.2-bin-hadoop2.7\"\n",
    "\n",
    "# Create a variable for our root path\n",
    "SPARK_HOME = os.environ['SPARK_HOME']\n",
    "\n",
    "#Add the following paths to the system path. Please check your installation\n",
    "#to make sure that these zip files actually exist. The names might change\n",
    "#as versions change.\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\",\"pyspark.zip\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\",\"py4j-0.10.7-src.zip\"))\n",
    "\n",
    "#Initialize SparkSession and SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "#from pyspark import SparkContext\n",
    "\n",
    "#Create a Spark Session\n",
    "MySparkSession = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"MiPrimer\") \\\n",
    "    .config(\"spark.executor.memory\", \"6g\") \\\n",
    "    .config(\"spark.cores.max\",\"4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "#Get the Spark Context from Spark Session    \n",
    "MySparkContext = MySparkSession.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.4.89.252:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MiPrimer</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=MiPrimer>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MySparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.executor.memory', '6g'),\n",
       " ('spark.app.name', 'MiPrimer'),\n",
       " ('spark.app.id', 'local-1551284444798'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.driver.host', '10.4.89.252'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.driver.port', '65511'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.master', 'local[2]'),\n",
       " ('spark.cores.max', '4')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MySparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------------------+-------+----------+------+-----------+-----------+\n",
      "|       TransactionID|CustomerID|               Date|Product|     Group|Amount|PaymentType|    Country|\n",
      "+--------------------+----------+-------------------+-------+----------+------+-----------+-----------+\n",
      "|7564e71a-3050-11e...|      4255|2018-07-18 02:36:00|      I|       Gym| 231.0|   American|     Sweden|\n",
      "|7565ad98-3050-11e...|     30514|2018-03-08 07:37:00|      D|       Gym|  59.7|      Check|     Mexico|\n",
      "|7565ad99-3050-11e...|      3853|2018-12-04 10:25:00|      B|    Travel|3782.0|       Cash|     Mexico|\n",
      "|7565ad9a-3050-11e...|     49729|2018-04-12 19:23:00|      I|  Gambling| 231.0|      Check|      Italy|\n",
      "|7565ad9b-3050-11e...|     33467|2018-02-01 23:17:00|      G|      Food|289.26| Mastercard|     Sweden|\n",
      "|7565ad9c-3050-11e...|     45120|2018-09-08 11:21:00|      I|Restaurant|  23.1|      Check|         UK|\n",
      "|7565ad9d-3050-11e...|      9965|2018-11-06 08:27:00|      C|    Travel|2590.0|      Check|Switzerland|\n",
      "|7565ad9e-3050-11e...|     20404|2018-08-05 00:47:00|      J|   Leisure| 12.93| Mastercard|    Denmark|\n",
      "|7565ad9f-3050-11e...|     46043|2018-08-04 05:07:00|      A|       Gym| 234.0|       Visa|     Brasil|\n",
      "|7565ada0-3050-11e...|      7053|2018-02-23 07:59:00|      E|       Gym| 93.47|       Visa|    Denmark|\n",
      "+--------------------+----------+-------------------+-------+----------+------+-----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+----------+--------------+\n",
      "|CustomerID|    CardNumber|\n",
      "+----------+--------------+\n",
      "|         0|15056453071315|\n",
      "|         1|15056453588315|\n",
      "|         2|15056453027428|\n",
      "|         3|15056453920562|\n",
      "|         4|15056453139712|\n",
      "|         5|15056453728136|\n",
      "|         6|15056453811382|\n",
      "|         7|15056453319623|\n",
      "|         8|15056453773603|\n",
      "|         9|15056453113544|\n",
      "+----------+--------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+---+-----------+\n",
      "|VAT|    Country|\n",
      "+---+-----------+\n",
      "| 21|      Italy|\n",
      "| 19|     France|\n",
      "| 18|    Germany|\n",
      "| 20|        USA|\n",
      "| 18|     Brasil|\n",
      "| 18|         UK|\n",
      "| 18|Switzerland|\n",
      "| 18|     Sweden|\n",
      "| 19|    Denmark|\n",
      "| 21|     Canada|\n",
      "+---+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactionDF = MySparkSession.read.csv(\"./transactions-asignment(2).csv\",header=True,inferSchema=True)\n",
    "\n",
    "customerDF = MySparkSession.read.csv(\"./customer-data-asignment(2).csv\",header=True,inferSchema=True)\n",
    "\n",
    "countryDF = MySparkSession.read.csv(\"./country-vat(3).csv\",header=True,inferSchema=True)\n",
    "\n",
    "transactionDF.show(10)\n",
    "customerDF.show(10)\n",
    "countryDF.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we should generate two new columns for year and month for transactionDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------------------+-------+----------+------+-----------+-----------+----+-----+\n",
      "|       TransactionID|CustomerID|               Date|Product|     Group|Amount|PaymentType|    Country|Year|Month|\n",
      "+--------------------+----------+-------------------+-------+----------+------+-----------+-----------+----+-----+\n",
      "|7564e71a-3050-11e...|      4255|2018-07-18 02:36:00|      I|       Gym| 231.0|   American|     Sweden|2018|   07|\n",
      "|7565ad98-3050-11e...|     30514|2018-03-08 07:37:00|      D|       Gym|  59.7|      Check|     Mexico|2018|   03|\n",
      "|7565ad99-3050-11e...|      3853|2018-12-04 10:25:00|      B|    Travel|3782.0|       Cash|     Mexico|2018|   12|\n",
      "|7565ad9a-3050-11e...|     49729|2018-04-12 19:23:00|      I|  Gambling| 231.0|      Check|      Italy|2018|   04|\n",
      "|7565ad9b-3050-11e...|     33467|2018-02-01 23:17:00|      G|      Food|289.26| Mastercard|     Sweden|2018|   02|\n",
      "|7565ad9c-3050-11e...|     45120|2018-09-08 11:21:00|      I|Restaurant|  23.1|      Check|         UK|2018|   09|\n",
      "|7565ad9d-3050-11e...|      9965|2018-11-06 08:27:00|      C|    Travel|2590.0|      Check|Switzerland|2018|   11|\n",
      "|7565ad9e-3050-11e...|     20404|2018-08-05 00:47:00|      J|   Leisure| 12.93| Mastercard|    Denmark|2018|   08|\n",
      "|7565ad9f-3050-11e...|     46043|2018-08-04 05:07:00|      A|       Gym| 234.0|       Visa|     Brasil|2018|   08|\n",
      "|7565ada0-3050-11e...|      7053|2018-02-23 07:59:00|      E|       Gym| 93.47|       Visa|    Denmark|2018|   02|\n",
      "+--------------------+----------+-------------------+-------+----------+------+-----------+-----------+----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "\n",
    "transactionDF = transactionDF.withColumn('Year',f.split(transactionDF.Date,'-')[0]) \\\n",
    "                            .withColumn('Month',f.split(transactionDF.Date,'-')[1])\n",
    "transactionDF.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Datasets for Product Marketing Depatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.a Build the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "marketingDF1 = transactionDF.groupby('country','group','Month') \\\n",
    "                            .agg(f.count('TransactionID').alias('Number_of_Transactions'),f.sum('Amount').alias('Total_Month'),f.avg('Amount').alias('Average_Month'))\n",
    "marketingDF2 = transactionDF.groupby('country','group','Month','Product') \\\n",
    "                            .agg(f.count('TransactionID').alias('Number_of_Transactions'),f.sum('Amount').alias('Total_Month'),f.avg('Amount').alias('Average_Month'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----+----------------------+------------------+------------------+\n",
      "|    country|     group|Month|Number_of_Transactions|       Total_Month|     Average_Month|\n",
      "+-----------+----------+-----+----------------------+------------------+------------------+\n",
      "|    Germany|  Gambling|   10|                  1016|346706.39999999956|341.24645669291294|\n",
      "|     Sweden|      Food|   10|                   937|248346.08999999898| 265.0438527214504|\n",
      "|    Denmark|Restaurant|   10|                   989| 105503.5499999999|106.67699696663286|\n",
      "|     Brasil|       Gym|   06|                   992|178634.63000000056|180.07523185483927|\n",
      "|      Italy|  Learning|   09|                   954|          194822.0|204.21593291404614|\n",
      "|        USA|       Gym|   05|                   982|181688.26000000053|185.01859470468486|\n",
      "|     Russia|      Food|   08|                   968|257216.28999999881|265.71930785123845|\n",
      "|     France|   Leisure|   10|                  1014| 41050.00000000013| 40.48323471400408|\n",
      "|Switzerland|   Leisure|   06|                  1030| 43207.61000000009|41.949135922330186|\n",
      "|      Italy|  Gambling|   01|                   991| 332869.9999999996| 335.8930373360238|\n",
      "+-----------+----------+-----+----------------------+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----------+----------+-----+-------+----------------------+-----------------+-----------------+\n",
      "|    country|     group|Month|Product|Number_of_Transactions|      Total_Month|    Average_Month|\n",
      "+-----------+----------+-----+-------+----------------------+-----------------+-----------------+\n",
      "|    Germany|   Leisure|   02|      F|                   100|4532.999999999997|45.32999999999997|\n",
      "|     Russia|      Food|   12|      B|                   101|48298.20000000004|478.2000000000004|\n",
      "|      Italy|Restaurant|   03|      C|                   105|          27195.0|            259.0|\n",
      "|     Canada|       Gym|   05|      G|                   109|          31501.0|            289.0|\n",
      "|     Mexico|  Gambling|   01|      G|                   108|          31212.0|            289.0|\n",
      "|Switzerland|  Learning|   11|      B|                    87|          30189.0|            347.0|\n",
      "|      Italy|    Travel|   06|      I|                   126|         291060.0|           2310.0|\n",
      "|     France|    Travel|   12|      D|                   102|          60894.0|            597.0|\n",
      "|        USA|   Leisure|   09|      G|                   108|3121.200000000002|28.90000000000002|\n",
      "|     Brasil|    Travel|   05|      B|                   107|         404674.0|           3782.0|\n",
      "+-----------+----------+-----+-------+----------------------+-----------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "marketingDF1.show(10)\n",
    "marketingDF2.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.b Number of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records for first DataFrame:  1008\n",
      "Number of records for second DataFrame:  10080\n"
     ]
    }
   ],
   "source": [
    "print('Number of records for first DataFrame: ', marketingDF1.count())\n",
    "print('Number of records for second DataFrame: ', marketingDF2.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Response to what is the country and the month with the highest \"total month amount\" for Group  Restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----+----------------------+------------------+------------------+\n",
      "|country|     group|Month|Number_of_Transactions|       Total_Month|     Average_Month|\n",
      "+-------+----------+-----+----------------------+------------------+------------------+\n",
      "|  Italy|Restaurant|   04|                  1059|118536.14999999997|111.93215297450422|\n",
      "+-------+----------+-----+----------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#    Country|Month|     Group|        TotalMonth|AvgMonth|Count|\n",
    "marketingDF1.createOrReplaceTempView('Table1')\n",
    "df2= MySparkSession.sql(\"Select * from Table1 where group='Restaurant' AND Total_Month=(Select max(Total_Month) from Table1 where group='Restaurant')\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Response to what is the Product with the highest sale about Gambling and what is the Country and the month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----+-------+----------------------+-----------+-------------+\n",
      "|country|   group|Month|Product|Number_of_Transactions|Total_Month|Average_Month|\n",
      "+-------+--------+-----+-------+----------------------+-----------+-------------+\n",
      "| Russia|Gambling|   10|      D|                   120|    71640.0|        597.0|\n",
      "+-------+--------+-----+-------+----------------------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#     Country|Month|   Group|Product|TotalMonth|AvgMonth|Count|\n",
    "marketingDF2.createOrReplaceTempView('Table2')\n",
    "df3=MySparkSession.sql(\"select * from Table2 where group='Gambling' AND Total_Month=(Select max(Total_Month) from Table2 where group='Gambling')\")\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Response to VAT to liquidate for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The country we have to pay the biggest VAT to is:  Row(CountryName='Russia', VAT=7968494.52)\n",
      "The country we have to pay the smallest VAT to is:  Row(CountryName='UK', VAT=6947854.91)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "df4= transactionDF.withColumnRenamed('Country','CountryName')\n",
    "df5= df4.join(countryDF,df4.CountryName==countryDF.Country,'left') \\\n",
    "        .drop('Country') \n",
    "df_VAT=df5.withColumn('VAT_Amount',df5.Amount-(df5.Amount/(1+(df5.VAT/100)))) \\\n",
    "          .groupBy('CountryName') \\\n",
    "          .agg(f.round(f.sum('VAT_Amount'),2).alias('VAT')) \n",
    "          \n",
    "print('The country we have to pay the biggest VAT to is: ',df_VAT.orderBy(col('VAT').desc()).first())\n",
    "print('The country we have to pay the smallest VAT to is: ',df_VAT.orderBy(col('VAT').asc()).first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Response to total amount for type of payment (except the payments in cash) to liquidate with their own bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|PaymentType| Total_Amount|\n",
      "+-----------+-------------+\n",
      "|       Visa|91,727,292.28|\n",
      "|      Check|91,842,289.77|\n",
      "| Mastercard|91,343,170.82|\n",
      "|     PayPal|90,871,507.94|\n",
      "|   American|90,893,043.24|\n",
      "+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "transactionDF.createOrReplaceTempView('Table3')\n",
    "df6=MySparkSession.sql(\"Select * from Table3 where PaymentType != 'Cash'\")\n",
    "\n",
    "df7= df6.withColumnRenamed('Country','CountryName')\n",
    "df8= df7.join(countryDF,df7.CountryName==countryDF.Country,'left') \\\n",
    "        .drop('Country') \\\n",
    "        .groupby('PaymentType') \\\n",
    "        .agg(f.format_number(f.sum('Amount'),2).alias('Total_Amount'))\n",
    "df8.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Response to Who is our best customer and what is his/her credit card number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------+\n",
      "|CustomerID|    CardNumber|  Amount|\n",
      "+----------+--------------+--------+\n",
      "|     14575|15056453501289|40981.03|\n",
      "+----------+--------------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "df9= transactionDF.withColumnRenamed('CustomerID','Customer_ID')\n",
    "df10= df9.join(customerDF,df9.Customer_ID==customerDF.CustomerID,'left')\\\n",
    "                   .drop('Customer_ID') \\\n",
    "                   .groupby('CustomerID','CardNumber')\\\n",
    "                   .agg(f.sum('Amount').alias('Amount'))\\\n",
    "                   .sort(col(\"Amount\").desc())\n",
    "df10.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Calculate the total income coming from USA by type of payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-----------------+\n",
      "|country|PaymentType|      TotalIncome|\n",
      "+-------+-----------+-----------------+\n",
      "|    USA|     PayPal|7415358.010000042|\n",
      "|    USA|       Cash|7636967.960000036|\n",
      "|    USA| Mastercard| 7750294.77000005|\n",
      "|    USA|   American|7497234.550000055|\n",
      "|    USA|       Visa|7837635.690000074|\n",
      "|    USA|      Check| 7827298.36000004|\n",
      "+-------+-----------+-----------------+\n",
      "\n",
      "+-----------+-----------------------------+\n",
      "|PaymentType|Total_Income_From_Outside_USA|\n",
      "+-----------+-----------------------------+\n",
      "|       Visa|          8.388965658998962E7|\n",
      "|      Check|          8.401499140998971E7|\n",
      "| Mastercard|          8.359287604999016E7|\n",
      "|     PayPal|          8.345614992998981E7|\n",
      "|       Cash|          8.382591183998904E7|\n",
      "|   American|           8.33958086899902E7|\n",
      "+-----------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "transactionDF.createOrReplaceTempView('Table4')\n",
    "df11= MySparkSession.sql(\"Select * from Table4 where Country = 'USA'\")\n",
    "df12= MySparkSession.sql(\"Select * from Table4 where Country != 'USA'\")\n",
    "\n",
    "df13= df11.groupby('country','PaymentType') \\\n",
    "          .agg(f.sum('Amount').alias('TotalIncome'))\n",
    "df14= df12.groupby('PaymentType')\\\n",
    "                   .agg(f.sum('Amount').alias('Total_Income_From_Outside_USA'))\n",
    "\n",
    "df13.show()\n",
    "df14.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Which is the relationship between the income from USA and from outside USA for every type of payment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------------------+-----------------+-----------------+\n",
      "|Payment_Type|Total_Income_From_Outside_USA|      TotalIncome|            Ratio|\n",
      "+------------+-----------------------------+-----------------+-----------------+\n",
      "|        Visa|          8.388965658998962E7|7837635.690000074|9.342791481799107|\n",
      "|       Check|          8.401499140998971E7| 7827298.36000004| 9.31654961648826|\n",
      "|  Mastercard|          8.359287604999016E7| 7750294.77000005|9.271477590225778|\n",
      "|      PayPal|          8.345614992998981E7|7415358.010000042|8.885334413606044|\n",
      "|        Cash|          8.382591183998904E7|7636967.960000036|9.110509855923608|\n",
      "|    American|           8.33958086899902E7|7497234.550000055|8.989941662259977|\n",
      "+------------+-----------------------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "df15= df14.withColumnRenamed(\"PaymentType\",\"Payment_Type\")\n",
    "df16= df15.join(df13,df15.Payment_Type==df13.PaymentType,'left')\\\n",
    "          .drop('country','PaymentType')\n",
    "df17 = df16.withColumn('Ratio',(df16.TotalIncome/df16.Total_Income_From_Outside_USA)*100) \n",
    "df17.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "MySparkContext.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
